CUDA 12.4
CUDNN 9.1.0

# 1. 클론
git clone https://github.com/kohya-ss/sd-scripts.git
cd sd-scripts

# 2. 가상환경 생성
python -m venv venv
.\venv\Scripts\activate  # Windows
# 또는
source venv/bin/activate  # Linux/Mac

# 3. PyTorch 설치 (CUDA 11.8 기준)
pip install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu118

# 4. 의존성 설치
pip install --upgrade -r requirements.txt
pip install xformers==0.0.23.post1 --index-url https://download.pytorch.org/whl/cu118

# 5. Accelerate 설정
accelerate config

질문에 답변:

컴퓨팅 환경: This machine
머신 타입: No distributed training
CPU only?: NO
torch dynamo?: NO
DeepSpeed?: NO
GPU ids: all (또는 0)
Mixed precision: 8GB VRAM의 경우 fp16, 12GB 이상의 경우 bf16


SDXL(Stable Diffusion XL) 모델 아키텍처는 여러 개의 대용량 파일로 구성되며 두 가지 주요 구성 요소는 기본 모델과 선택적 정제 모델입니다..safetensors. 모델 파일 크기는 사용된 파일 형식(예: 또는 .ckpt) 에 따라 달라질 수 있습니다 . 
공식 SDXL 1.0 파일
공식 SDXL 1.0 릴리스의 일반적인 파일 크기는 다음과 같습니다. 
기본 모델: 약 6.94GB. 이 모델은 텍스트 프롬프트에서 초기 이미지를 생성하는 데 사용됩니다.
리파이너 모델: 약 6.08GB. 리파이너는 기본 모델에서 생성된 이미지에 세부적인 정보를 추가하고 품질을 개선하는 두 번째 단계로 사용됩니다.
전체 파이프라인의 총 크기: 기본 모델과 정제 모델의 결합된 크기는 약 13GB이지만, 많은 사용자는 이제 더 빠른 워크플로를 위해 기본 모델을 주로 사용합니다. 


3. 이미지 크기 조정 및 버킷화
최적 해상도: 훈련하려는 기본 모델에 따라 권장 해상도가 다릅니다.
Stable Diffusion 1.5: 512x512, 512x768, 768x512 등
SDXL: 1024x1024
버킷화 (Bucketing): Kohya_ss는 여러 다른 해상도의 이미지를 효율적으로 처리하는 '버킷' 기능을 제공합니다.
GUI에서 사전 처리 탭 선택: Kohya GUI의 Utilities 탭에서 Prepare training data를 선택합니다.
폴더 설정: Source directory에 원본 이미지 폴더를, Destination directory에 처리된 이미지를 저장할 폴더를 지정합니다.
최소/최대 해상도 설정: Min resolution과 Max resolution을 설정하고, Use buckets를 활성화합니다.
자동 크기 조정: Process images를 실행하면 이미지가 지정된 버킷 해상도에 맞게 자동으로 리사이즈되고 크롭됩니다. 


💡 추가 팁
최대 3000 스텝 또는 30 에포크 권장 GitHub
50장의 학습 이미지와 4회 반복 권장 GitHub
VRAM별 배치 크기:

8GB: batch_size 1-2 GitHub
12GB: batch_size 2-3 GitHub
더 높은 VRAM: batch_size 5+ GitHub


## 💡 반복 횟수 선택 가이드

| 이미지 수 | 권장 반복 | 폴더명 예시 | 10 에포크 시 총 스텝 |
|----------|---------|------------|-------------------|
| 10장 | 10회 | `10_character` | 1000 스텝 |
| 20장 | 5회 | `5_character` | 1000 스텝 |
| 50장 | 4회 | `4_character` | 2000 스텝 |
| 100장 | 2회 | `2_character` | 2000 스텝 |
| 200장 | 1회 | `1_character` | 2000 스텝 |

**목표:** 총 스텝이 **1500~3000** 정도가 되도록 조절



고품질 (일관된 스타일/포즈/의상):
→ 4회 반복으로 충분

저품질 (다양한 각도/의상/배경):
→ 10~20회 필요할 수도
```

### **2. 목표가 다름**
```
Gemini 기준: 캐릭터 얼굴/특징 확실히 학습
Kohya 문서: 과적합(overfitting) 방지
```

### **3. 총 스텝 수 계산 방식**
```
50장 × 4회 × 10 에포크 = 2000 스텝
50장 × 10회 × 5 에포크 = 2500 스텝
50장 × 20회 × 2 에포크 = 2000 스텝
```
결국 **총 스텝이 비슷**하면 결과도 비슷해요!

---

## 📊 실전 테스트 결과 (커뮤니티 경험)

| 반복 횟수 | 이미지 수 | 에포크 | 총 스텝 | 결과 |
|----------|----------|-------|---------|------|
| 4회 | 50장 | 10 | 2000 | ⭐⭐⭐⭐ 균형 잡힘 |
| 10회 | 50장 | 5 | 2500 | ⭐⭐⭐⭐⭐ 강한 학습 |
| 20회 | 50장 | 3 | 3000 | ⚠️ 과적합 위험 |
| 2회 | 100장 | 10 | 2000 | ⭐⭐⭐⭐ 자연스러움 |

---

## 🎯 실전 가이드

### **상황별 권장 설정**

#### **📷 고품질 데이터셋 (일관된 캐릭터/스타일)**
```
이미지: 50장
반복: 4~6회
에포크: 8~10
총 스텝: 1600~3000

예: 4_character_name
```

#### **🎨 다양한 데이터셋 (여러 포즈/의상/배경)**
```
이미지: 50장
반복: 8~12회
에포크: 5~8
총 스텝: 2000~4800

예: 10_character_name
```

#### **⚡ 빠른 테스트 (품질 확인용)**
```
이미지: 30장
반복: 5회
에포크: 5
총 스텝: 750

예: 5_test_character
```

#### **🏆 프로덕션 품질 (상업용/고품질)**
```
이미지: 100장+
반복: 3~5회
에포크: 10~15
총 스텝: 3000~7500

예: 3_character_name
```

---

## 💡 **내 추천: 점진적 테스트**

### **1단계: 낮게 시작**
```
폴더: 4_character
에포크: 5
→ 1000 스텝에서 결과 확인
```

### **2단계: 필요시 증가**
```
만족스럽지 않으면:
폴더: 8_character
에포크: 5
→ 2000 스텝에서 재확인
```

### **3단계: 최적점 찾기**
```
과적합 보이면: 반복 횟수 줄이기
언더피팅이면: 반복 횟수 늘리기
```

---

## 🔬 과학적(?) 접근

### **총 스텝 기준 가이드:**
```
1000~1500 스텝: 가벼운 스타일 LoRA
2000~3000 스텝: 캐릭터 LoRA (일반)
3000~5000 스텝: 디테일한 캐릭터
5000+ 스텝: 복잡한 컨셉/다중 캐릭터